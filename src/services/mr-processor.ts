import type { GitLabDependencies, OllamaDependencies, OpenAIDependencies, CodexDependencies } from "../types/dependencies.js";
import type { MergeRequest } from "../types/gitlab.js";
import type { LLMProvider } from "../types/llm.js";
import { LLM_PROVIDERS } from "../constants/llm-providers.js";
import { EXCLUDE_TARGET_BRANCHES, EXCLUDE_TARGET_BRANCH_PATTERNS } from "../constants/branch-filters.js";
import * as gitlabClient from "./gitlab-client.js";
import * as ollamaClient from "./ollama-client.js";
import * as openaiClient from "./openai-client.js";
import * as codexClient from "./codex-client.js";
import { buildReviewPrompt } from "../utils/prompt-builder.js";
import { calculateTokenUsage } from "../utils/token-counter.js";
import { addUsageEntry } from "../utils/usage-logger.js";
import { readFileSync, existsSync } from "fs";
import { join } from "path";

/**
 * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
 * AGENTS_FILE í™˜ê²½ ë³€ìˆ˜ë¡œ íŒŒì¼ ê²½ë¡œ ì§€ì • ê°€ëŠ¥ (ê¸°ë³¸ê°’: AGENTS.md)
 */
const loadSystemPrompt = (agentsFile = process.env.AGENTS_FILE || "AGENTS.md"): string | undefined => {
  const agentsPath = join(process.cwd(), agentsFile);
  
  if (existsSync(agentsPath)) {
    try {
      console.log(`ğŸ“œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ: ${agentsFile}`);
      return readFileSync(agentsPath, "utf-8");
    } catch {
      console.warn(`âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: ${agentsFile}`);
      return undefined;
    }
  }
  console.warn(`âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: ${agentsFile}`);
  return undefined;
};

/**
 * LLM í´ë¼ì´ì–¸íŠ¸ íƒ€ì… (Ollama, OpenAI, ë˜ëŠ” Codex)
 */
export type LLMDependencies = OllamaDependencies | OpenAIDependencies | CodexDependencies;

/**
 * ì²˜ë¦¬ ì¤‘ì¸ MRì„ ì¶”ì í•˜ê¸° ìœ„í•œ ìƒíƒœ
 */
export interface ProcessingState {
  processing: Set<number>;
}

/**
 * ì²˜ë¦¬ ìƒíƒœë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 */
export const createProcessingState = (): ProcessingState => ({
  processing: new Set(),
});

/**
 * ì²˜ë¦¬ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 */
const handleProcessingError = async (gitlabDeps: GitLabDependencies, projectId: string, mrIid: number, error: Error): Promise<void> => {
  try {
    const errorComment = `## âš ï¸ AI ë¦¬ë·° ì‹¤íŒ¨

AI ë¦¬ë·° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:

\`\`\`
${error.message}
\`\`\`

ë‚˜ì¤‘ì— ë‹¤ì‹œ ë¦¬ë·° ë°›ê¸°ë¥¼ ì›í•  ì‹œ ai-review ë¼ë²¨ì„ ì œê±°í•´ì£¼ì„¸ìš”.`;

    await gitlabClient.addComment(gitlabDeps, projectId, mrIid, errorComment);
  } catch (commentError) {
    console.error("ì˜¤ë¥˜ ì½”ë©˜íŠ¸ ì¶”ê°€ ì‹¤íŒ¨:", commentError);
  }
};

/**
 * ë‹¨ì¼ MRì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 */
export const processSingleMR = async (
  gitlabDeps: GitLabDependencies,
  llmDeps: LLMDependencies,
  llmProvider: LLMProvider,
  projectId: string,
  aiReviewLabel: string,
  llmModel: string,
  mr: MergeRequest,
  state: ProcessingState
): Promise<void> => {
  state.processing.add(mr.iid);

  // MR URL ì‚¬ìš© (GitLab APIì—ì„œ ì œê³µ)
  const mrUrl = mr.web_url;
  let diffInfo: { fileCount: number; totalSizeBytes: number; totalLines: number } | undefined;
  let prompt = "";
  let review = "";

  try {
    console.log(`\nğŸ“ MR !${mr.iid} ì²˜ë¦¬ ì‹œì‘: ${mr.title}`);

    const changes = await gitlabClient.getMergeRequestChanges(gitlabDeps, projectId, mr.iid);

    if (changes.length === 0) {
      console.log(`â­ï¸  MR !${mr.iid}ì— ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.`);
      return;
    }

    console.log(`âœ“ ${changes.length}ê°œì˜ íŒŒì¼ ë³€ê²½ ë°œê²¬`);

    // diff í¬ê¸° ë¡œê¹…
    const totalDiffSize = changes.reduce((sum, c) => sum + c.diff.length, 0);
    const totalLines = changes.reduce((sum, c) => sum + c.diff.split('\n').length, 0);
    const sizeInKB = (totalDiffSize / 1024).toFixed(1);
    console.log(`ğŸ“Š ì „ì²´ diff í¬ê¸°: ${sizeInKB}KB`);

    // diff ì •ë³´ ì €ì¥ (ë¡œê¹…ìš©)
    diffInfo = {
      fileCount: changes.length,
      totalSizeBytes: totalDiffSize,
      totalLines,
    };

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (AGENTS.md)
    const agentsFile = process.env.AGENTS_FILE || "AGENTS.md";
    const systemPrompt = loadSystemPrompt(agentsFile);
    const promptResult = buildReviewPrompt(mr, changes, systemPrompt);
    prompt = promptResult.prompt;
    const { diffSize, overheadSize } = promptResult;

    // í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë¶„ì„ ë¡œê¹…
    const totalPromptSize = diffSize.characters + overheadSize.characters;
    const diffRatio = ((diffSize.characters / totalPromptSize) * 100).toFixed(1);
    console.log(`ğŸ“‹ í”„ë¡¬í”„íŠ¸ êµ¬ì„±:`);
    console.log(`  ğŸ“„ ìˆœìˆ˜ diff: ${diffSize.characters.toLocaleString()}ì (${diffSize.lines}ì¤„) - ${diffRatio}%`);
    console.log(`  ğŸ“ ì˜¤ë²„í—¤ë“œ í•©ê³„: ${overheadSize.characters.toLocaleString()}ì (${overheadSize.lines}ì¤„) - ${(100 - parseFloat(diffRatio)).toFixed(1)}%`);
    console.log(`     â””â”€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (${agentsFile}): ${overheadSize.breakdown.systemPrompt.characters.toLocaleString()}ì (${overheadSize.breakdown.systemPrompt.lines}ì¤„)`);
    console.log(`     â””â”€ MR í—¤ë”: ${overheadSize.breakdown.mrHeader.characters.toLocaleString()}ì (${overheadSize.breakdown.mrHeader.lines}ì¤„)`);

    console.log(`ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ AI ë¦¬ë·° ìš”ì²­ ì¤‘...`);
    
    if (llmProvider === LLM_PROVIDERS.OLLAMA) {
      review = await ollamaClient.queryOllamaModelStream(
        llmDeps as OllamaDependencies,
        llmModel,
        prompt,
        () => {} // ì²­í¬ëŠ” ë¬´ì‹œí•˜ê³  ì „ì²´ ì‘ë‹µë§Œ ìˆ˜ì§‘
      );
    } else if (llmProvider === LLM_PROVIDERS.OPENAI) {
      review = await openaiClient.queryOpenAIModelStream(
        llmDeps as OpenAIDependencies,
        llmModel,
        prompt,
        () => {} // ì²­í¬ëŠ” ë¬´ì‹œí•˜ê³  ì „ì²´ ì‘ë‹µë§Œ ìˆ˜ì§‘
      );
    } else {
      review = await codexClient.queryCodexModelStream(
        llmDeps as CodexDependencies,
        prompt,
        () => {} // ì²­í¬ëŠ” ë¬´ì‹œí•˜ê³  ì „ì²´ ì‘ë‹µë§Œ ìˆ˜ì§‘
      );
    }

    await gitlabClient.addComment(gitlabDeps, projectId, mr.iid, review);

    // í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° ë° ë¡œê¹…
    const tokenUsage = calculateTokenUsage(prompt, review, llmModel);
    const logEntry = addUsageEntry({
      mrTitle: mr.title,
      mrUrl,
      projectId,
      mrIid: mr.iid,
      model: llmModel,
      provider: llmProvider,
      tokenUsage,
      status: "success",
      diffInfo,
    });

    console.log(`ğŸ’° ì˜ˆìƒ ë¹„ìš©: $${logEntry.estimatedCostUSD.toFixed(4)} (â‚©${logEntry.estimatedCostKRW.toLocaleString()})`);
    console.log(`âœ… MR !${mr.iid} ì²˜ë¦¬ ì™„ë£Œ\n`);
  } catch (error) {
    console.error(`âŒ MR !${mr.iid} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);

    // ì‹¤íŒ¨ ì‹œì—ë„ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (í† í° ì¶”ì •ì¹˜)
    if (prompt) {
      const errorTokenUsage = calculateTokenUsage(prompt, "", llmModel);
      addUsageEntry({
        mrTitle: mr.title,
        mrUrl,
        projectId,
        mrIid: mr.iid,
        model: llmModel,
        provider: llmProvider,
        tokenUsage: errorTokenUsage,
        status: "failed",
        errorMessage: error instanceof Error ? error.message : String(error),
        diffInfo,
      });
    }

    if (error instanceof Error) {
      await handleProcessingError(gitlabDeps, projectId, mr.iid, error);
    }
  } finally {
    try {
      await gitlabClient.addAiReviewLabel(gitlabDeps, projectId, mr.iid, aiReviewLabel);
    } catch (labelError) {
      console.error(`ë¼ë²¨ ì¶”ê°€ ì‹¤íŒ¨:`, labelError);
    }
    state.processing.delete(mr.iid);
  }
};

/**
 * ëŒ€ìƒ MRë“¤ì„ ì°¾ì•„ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 */
export const processMergeRequests = async (
  gitlabDeps: GitLabDependencies,
  llmDeps: LLMDependencies,
  llmProvider: LLMProvider,
  projectId: string,
  aiReviewLabel: string,
  excludeTargetBranches: string[],
  excludeTargetBranchPatterns: string[],
  llmModel: string,
  state: ProcessingState
): Promise<void> => {
  try {
    console.log("\nğŸ” AI ë¦¬ë·° ëŒ€ìƒ MR ê²€ìƒ‰ ì¤‘...");

    const targetMRs = await gitlabClient.getTargetMergeRequests(
      gitlabDeps,
      projectId,
      aiReviewLabel,
      excludeTargetBranches,
      excludeTargetBranchPatterns
    );

    if (targetMRs.length === 0) {
      console.log("â„¹ï¸  ì²˜ë¦¬í•  MRì´ ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    console.log(`âœ“ ${targetMRs.length}ê°œì˜ MR ë°œê²¬`);

    for (const mr of targetMRs) {
      if (state.processing.has(mr.iid)) {
        console.log(`â­ï¸  MR !${mr.iid}ëŠ” ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.`);
        continue;
      }

      await processSingleMR(gitlabDeps, llmDeps, llmProvider, projectId, aiReviewLabel, llmModel, mr, state);
    }
  } catch (error) {
    console.error("MR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
  }
};

/**
 * LLM ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.
 */
export const checkLLMAvailability = async (
  llmDeps: LLMDependencies,
  llmProvider: LLMProvider,
  model: string
): Promise<boolean> => {
  if (llmProvider === LLM_PROVIDERS.OLLAMA) {
    return ollamaClient.checkModelAvailability(llmDeps as OllamaDependencies, model);
  } else if (llmProvider === LLM_PROVIDERS.OPENAI) {
    return openaiClient.checkModelAvailability(llmDeps as OpenAIDependencies, model);
  } else {
    return codexClient.checkModelAvailability(llmDeps as CodexDependencies);
  }
};

/**
 * Webhookì—ì„œ MR IDë¡œ ì§ì ‘ ì²˜ë¦¬ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
 */
export const processMergeRequestById = async (
  gitlabDeps: GitLabDependencies,
  llmDeps: LLMDependencies,
  llmProvider: LLMProvider,
  projectId: string,
  aiReviewLabel: string,
  llmModel: string,
  mrIid: number,
  state: ProcessingState
): Promise<{ success: boolean; message: string }> => {
  // ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
  if (state.processing.has(mrIid)) {
    return { success: false, message: `MR !${mrIid}ëŠ” ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.` };
  }

  // MR ì¡°íšŒ
  const mr = await gitlabClient.getMergeRequestById(gitlabDeps, projectId, mrIid);

  if (!mr) {
    return { success: false, message: `MR !${mrIid}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.` };
  }

  // MR ìƒíƒœ í™•ì¸
  if (mr.state !== "opened") {
    return { success: false, message: `MR !${mrIid}ëŠ” ì—´ë¦° ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤. (í˜„ì¬: ${mr.state})` };
  }

  // ë¦¬ë·° ëŒ€ìƒì¸ì§€ í™•ì¸
  const targetCheck = gitlabClient.isReviewTarget(
    mr,
    aiReviewLabel,
    EXCLUDE_TARGET_BRANCHES,
    EXCLUDE_TARGET_BRANCH_PATTERNS
  );

  if (!targetCheck.isTarget) {
    return { success: false, message: `MR !${mrIid}ëŠ” ë¦¬ë·° ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤. (${targetCheck.reason})` };
  }

  // ì²˜ë¦¬ ì‹œì‘
  await processSingleMR(gitlabDeps, llmDeps, llmProvider, projectId, aiReviewLabel, llmModel, mr, state);

  return { success: true, message: `MR !${mrIid} ì²˜ë¦¬ ì™„ë£Œ` };
};
